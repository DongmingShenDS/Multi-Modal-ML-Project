{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28901f3e-03e5-40fd-a944-e049b1b756ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shendongming/miniconda3/envs/myjulia/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import warnings\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor, log_evaluation, early_stopping\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import scipy as sp\n",
    "from sklearn.metrics import confusion_matrix as sk_cmatrix\n",
    "from sklearn.model_selection import KFold\n",
    "from joblib import dump\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af8e5a9e-f0c9-45da-8dbd-7d385269eb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This copy of Interpretable AI software is for academic purposes only and not for commercial use.\n"
     ]
    }
   ],
   "source": [
    "import interpretableai\n",
    "from julia.api import Julia\n",
    "jl = Julia(compiled_modules=False)\n",
    "# interpretableai.install_julia()\n",
    "# interpretableai.install_system_image()\n",
    "import os\n",
    "os.environ['JULIA_NUM_THREADS'] = '50'\n",
    "from interpretableai import iai\n",
    "# iai.add_julia_processes(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9346cffd-17e9-4d77-825f-364cbe1cc70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(model, train_data):\n",
    "    feature_importances = model.booster_.feature_importance(importance_type='gain')\n",
    "    feature_importance_df = pd.DataFrame({'Feature': train_data.columns, 'Importance': feature_importances})\n",
    "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "    return feature_importance_df\n",
    "\n",
    "def feature_importance_group(model, train_data):\n",
    "    feature_importances = model.booster_.feature_importance(importance_type='gain')\n",
    "    feature_names = train_data.columns\n",
    "    # Create a DataFrame for feature importances\n",
    "    feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "    # Group by the feature name pattern and sum their importances\n",
    "    # Strip the digits using a regular expression to group\n",
    "    feature_importance_df['Feature_Group'] = feature_importance_df['Feature'].str.replace(r'\\d+', '', regex=True)\n",
    "    grouped_importance = feature_importance_df.groupby('Feature_Group', as_index=False)['Importance'].sum()\n",
    "    # Sort by the summed importance\n",
    "    grouped_importance = grouped_importance.sort_values(by='Importance', ascending=False)\n",
    "    return grouped_importance\n",
    "\n",
    "def plot_feature_importance(grouped_importance_df):\n",
    "    plt.barh(grouped_importance_df['Feature_Group'], grouped_importance_df['Importance'], color='skyblue')\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.ylabel('Feature Group')\n",
    "    plt.title('Feature Importance by Group')\n",
    "    plt.gca().invert_yaxis()  # To display the highest importance at the top\n",
    "    plt.show()\n",
    "\n",
    "class OptimizedRounder(object):\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        preds = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3, 4])\n",
    "        return -cohen_kappa_score(y, preds, weights='quadratic')\n",
    "    def fit(self, X, y):\n",
    "        loss_partial = partial(self._kappa_loss, X = X, y = y)\n",
    "        initial_coef = [0.5, 1.5, 2.5, 3.5]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n",
    "    def predict(self, X, coef):\n",
    "        preds = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3, 4])\n",
    "        return preds\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']\n",
    "\n",
    "def PreProcessTrain(\n",
    "    df, bert_emb, breed_emb, beit_emb, new_cols_ALL,\n",
    "    bert=True, beit=True, breed=True, txt=True, meta=True, senti=True, newcols=True\n",
    "):\n",
    "    name = 'train'\n",
    "    # df = pd.read_csv(f'petfinder-adoption-prediction/{name}/{name}.csv')\n",
    "    txt_emb = pd.read_csv(f'petfinder-adoption-prediction/{name}/txt_emb.csv').drop(columns=['Description', 'PhotoAmt'])\n",
    "    metadata_gr = pd.read_csv(f'petfinder-adoption-prediction/{name}/metadata_gr.csv')\n",
    "    sentiment_gr = pd.read_csv(f'petfinder-adoption-prediction/{name}/sentiment_gr.csv')\n",
    "    \n",
    "    if beit:\n",
    "        beit_emb = pd.read_csv(f'petfinder-adoption-prediction/{name}/beit_emb.csv')\n",
    "        beit_emb = beit_emb.drop(columns=['Description', 'PhotoAmt'])\n",
    "    df = pd.merge(df, beit_emb, on=['PetID'], how='left')\n",
    "    \n",
    "    if bert: df = pd.merge(df, bert_emb, on=['PetID'], how='left')\n",
    "    if breed: \n",
    "        df = pd.merge(df, breed_emb, left_on=['Breed1'], right_on=['BreedID'], how='left')\n",
    "        df = df.drop(columns=['BreedID'])    \n",
    "    if txt: df = pd.merge(df, txt_emb, on=['PetID'], how='left')\n",
    "    if meta: df = pd.merge(df, metadata_gr, on=['PetID'], how='left')\n",
    "    if senti: df = pd.merge(df, sentiment_gr, on=['PetID'], how='left')\n",
    "    if newcols: df = pd.merge(df, new_cols_ALL, on=['PetID'], how='left')\n",
    "    \n",
    "    X = df.drop(columns=['AdoptionSpeed', 'Name', 'Description', 'PetID', 'RescuerID'])  # Features\n",
    "    Y = df['AdoptionSpeed']\n",
    "    \n",
    "    # non_numeric_columns = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3']\n",
    "    # for col in non_numeric_columns: X[col] = X[col].astype('category')\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "def PreProcessTest(\n",
    "    df, bert_emb, breed_emb, beit_emb, new_cols_ALL,\n",
    "    bert=True, beit=True, breed=True, txt=True, meta=True, senti=True, newcols=True\n",
    "):\n",
    "    name = 'test'\n",
    "    # df = pd.read_csv(f'petfinder-adoption-prediction/{name}/{name}.csv')\n",
    "    txt_emb = pd.read_csv(f'petfinder-adoption-prediction/{name}/txt_emb.csv').drop(columns=['Description', 'PhotoAmt'])\n",
    "    metadata_gr = pd.read_csv(f'petfinder-adoption-prediction/{name}/metadata_gr.csv')\n",
    "    sentiment_gr = pd.read_csv(f'petfinder-adoption-prediction/{name}/sentiment_gr.csv')\n",
    "    \n",
    "    if beit:\n",
    "        beit_emb = pd.read_csv(f'petfinder-adoption-prediction/{name}/beit_emb.csv')\n",
    "        beit_emb = beit_emb.drop(columns=['Description', 'PhotoAmt'])\n",
    "    df = pd.merge(df, beit_emb, on=['PetID'], how='left')\n",
    "    \n",
    "    if bert: df = pd.merge(df, bert_emb, on=['PetID'], how='left')\n",
    "    if breed: \n",
    "        df = pd.merge(df, breed_emb, left_on=['Breed1'], right_on=['BreedID'], how='left')\n",
    "        df = df.drop(columns=['BreedID'])\n",
    "    if txt: df = pd.merge(df, txt_emb, on=['PetID'], how='left')\n",
    "    if meta: df = pd.merge(df, metadata_gr, on=['PetID'], how='left')\n",
    "    if senti: df = pd.merge(df, sentiment_gr, on=['PetID'], how='left')\n",
    "    if newcols: df = pd.merge(df, new_cols_ALL, on=['PetID'], how='left')\n",
    "    \n",
    "    X = df.drop(columns=['Name', 'Description', 'PetID', 'RescuerID'])\n",
    "    \n",
    "    # non_numeric_columns = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3']\n",
    "    # for col in non_numeric_columns: X[col] = X[col].astype('category')\n",
    "    \n",
    "    return X\n",
    "\n",
    "def TrainLGBMReg(params, X_train, y_train):\n",
    "    categorical_features = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3']\n",
    "    X_train[categorical_features] = X_train[categorical_features].astype('category')\n",
    "    params['metric'] = 'rmse'\n",
    "    params['subsample'] = None\n",
    "    params['subsample_freq'] = None\n",
    "    model = LGBMRegressor(**params)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        categorical_feature=categorical_features\n",
    "    )\n",
    "    preds = model.predict(X_train)\n",
    "    optR = OptimizedRounder()\n",
    "    optR.fit(preds, y_train.values)\n",
    "    coefficients = optR.coefficients()\n",
    "    pred_y = optR.predict(preds, coefficients)\n",
    "    print(cohen_kappa_score(y_train, pred_y, weights='quadratic'))\n",
    "    return model, optR, coefficients\n",
    "\n",
    "def TestResultDF_LGBMReg(model, optR, coef, X_test, name):\n",
    "    preds = model.predict(X_test) \n",
    "    pred_y = optR.predict(preds, coef)\n",
    "    test_result = pd.DataFrame({'PetID': test_data['PetID'], 'AdoptionSpeed': pred_y})\n",
    "    print(test_result)\n",
    "    test_result.to_csv(name, index=False)\n",
    "\n",
    "def TRAINMODEL(\n",
    "    bert=True, beit=True, breed=True, txt=True, meta=True, senti=True, newcols=True,\n",
    "    pca_bert=200, pca_breed=200, pca_beit=500,\n",
    "    params=None,\n",
    "    save_address=None,\n",
    "):\n",
    "    if not params or not save_address: return \n",
    "    \n",
    "    # read files \n",
    "    bert_pca200_ALL = pd.read_csv('petfinder-adoption-prediction/train/bert_pca200_ALL.csv') # 100 enough\n",
    "    breed_pca200_ALL = pd.read_csv('petfinder-adoption-prediction/train/breed_pca200_ALL.csv') # 100 enough\n",
    "    beit_pca768_ALL = pd.read_csv('petfinder-adoption-prediction/train/beit_pca768_ALL.csv') # 500 enough?\n",
    "    bert_emb = bert_pca200_ALL[['PetID'] + [f'bert_pc_{i}' for i in range(1, pca_bert + 1)]] # PetID\n",
    "    breed_emb = breed_pca200_ALL[['BreedID'] + [f'breed_pc_{i}' for i in range(1, pca_breed + 1)]] # BreedID\n",
    "    beit_emb = beit_pca768_ALL[['PetID'] + [f'beit_pc_{i}' for i in range(1, pca_beit + 1)]] # PetID\n",
    "    new_cols_ALL = pd.read_csv('petfinder-adoption-prediction/train/new_cols_ALL.csv') # PetID\n",
    "    \n",
    "    # parse inpput\n",
    "    test_data = pd.read_csv(f'petfinder-adoption-prediction/test/test.csv')\n",
    "    X_train, y_train = PreProcessTrain(\n",
    "        bert_emb, breed_emb, beit_emb, new_cols_ALL,\n",
    "        bert, beit, breed, txt, meta, senti, newcols\n",
    "    )\n",
    "    X_test = PreProcessTest(\n",
    "        bert_emb, breed_emb, beit_emb, new_cols_ALL,\n",
    "        bert, beit, breed, txt, meta, senti, newcols\n",
    "    )\n",
    "    \n",
    "    # train model\n",
    "    cat, optR, coefficients = TrainLGBMReg(params, X_train, y_train)\n",
    "    \n",
    "    # evaluate model\n",
    "    imp = feature_importance_group(cat, X_train)\n",
    "    plot_feature_importance(imp)\n",
    "    \n",
    "    # save result\n",
    "    TestResultDF_LGBMReg(cat, optR, coefficients, X_test, f'Results/{save_address}.csv')\n",
    "    \n",
    "    return cat, optR, coefficients, save_address\n",
    "\n",
    "def OptunaTune(X_train_in, Y_train_in, initial_params=None, nt=100, nj=4):\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train_in, Y_train_in, test_size=0.2, random_state=42, stratify=Y_train_in)\n",
    "\n",
    "    def objective(trial):\n",
    "        if initial_params and trial.number == 0:\n",
    "            param = initial_params\n",
    "            print(f\"using initial param for trial {trial.number}\")\n",
    "        else:            \n",
    "            param = {\n",
    "                'max_depth': trial.suggest_int('max_depth', 15, 80),\n",
    "                'minbucket': trial.suggest_int('minbucket', 1, 20),\n",
    "                'ls_num_tree_restarts': trial.suggest_int('ls_num_tree_restarts', 15, 100),\n",
    "                'regression_lambda': trial.suggest_float('regression_lambda', 0.01, 0.1),\n",
    "            }    \n",
    "\n",
    "        grid = iai.GridSearch(\n",
    "            iai.OptimalTreeRegressor(\n",
    "                **param, \n",
    "            ),\n",
    "        )\n",
    "        start_time = time.time()\n",
    "        grid.fit(X_train, y_train)\n",
    "        preds = grid.predict(X_valid)\n",
    "        \n",
    "        optR = OptimizedRounder()\n",
    "        optR.fit(preds, y_valid.values)\n",
    "        coefficients = optR.coefficients()\n",
    "        pred_valid = optR.predict(preds, coefficients)\n",
    "\n",
    "        loss = cohen_kappa_score(y_valid, pred_valid, weights='quadratic')\n",
    "        end_time = time.time()\n",
    "        print(f'loss: {loss}. params: {param}. time: {end_time - start_time}')\n",
    "        return loss\n",
    "\n",
    "    # Create a study object and optimize the objective function.\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=nt, n_jobs=nj, show_progress_bar=True)\n",
    "\n",
    "    print('Number of finished trials:', len(study.trials))\n",
    "    print('Best trial:', study.best_trial.params)\n",
    "    return study.best_trial.params\n",
    "\n",
    "categorical_features = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e0ff130-a597-40bc-a6ae-216b59882aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert=True\n",
    "beit=False \n",
    "breed=True\n",
    "txt=True\n",
    "meta=False\n",
    "senti=False\n",
    "newcols=True\n",
    "pca_bert=5\n",
    "pca_breed=5\n",
    "pca_beit=5\n",
    "\n",
    "# read files \n",
    "bert_pca200_ALL = pd.read_csv('petfinder-adoption-prediction/train/bert_pca200_ALL.csv') # 100 enough\n",
    "breed_pca200_ALL = pd.read_csv('petfinder-adoption-prediction/train/breed_pca200_ALL.csv') # 100 enough\n",
    "beit_pca768_ALL = pd.read_csv('petfinder-adoption-prediction/train/beit_pca768_ALL.csv') # 500 enough?\n",
    "bert_emb = bert_pca200_ALL[['PetID'] + [f'bert_pc_{i}' for i in range(1, pca_bert + 1)]] # PetID\n",
    "breed_emb = breed_pca200_ALL[['BreedID'] + [f'breed_pc_{i}' for i in range(1, pca_breed + 1)]] # BreedID\n",
    "beit_emb = beit_pca768_ALL[['PetID'] + [f'beit_pc_{i}' for i in range(1, pca_beit + 1)]] # PetID\n",
    "new_cols_ALL = pd.read_csv('petfinder-adoption-prediction/train/new_cols_ALL.csv') # PetID\n",
    "\n",
    "# train\n",
    "name = 'train'\n",
    "df_train = pd.read_csv(f'petfinder-adoption-prediction/{name}/{name}.csv')\n",
    "txt_emb = pd.read_csv(f'petfinder-adoption-prediction/{name}/txt_emb.csv').drop(columns=['Description', 'PhotoAmt'])\n",
    "metadata_gr = pd.read_csv(f'petfinder-adoption-prediction/{name}/metadata_gr.csv')\n",
    "sentiment_gr = pd.read_csv(f'petfinder-adoption-prediction/{name}/sentiment_gr.csv')\n",
    "if beit:\n",
    "    beit_emb = pd.read_csv(f'petfinder-adoption-prediction/{name}/beit_emb.csv')\n",
    "    beit_emb = beit_emb.drop(columns=['Description', 'PhotoAmt'])\n",
    "df_train = pd.merge(df_train, beit_emb, on=['PetID'], how='left')\n",
    "if bert: df_train = pd.merge(df_train, bert_emb, on=['PetID'], how='left')\n",
    "if breed: \n",
    "    df_train = pd.merge(df_train, breed_emb, left_on=['Breed1'], right_on=['BreedID'], how='left')\n",
    "    df_train = df_train.drop(columns=['BreedID'])    \n",
    "if txt: df_train = pd.merge(df_train, txt_emb, on=['PetID'], how='left')\n",
    "if meta: df_train = pd.merge(df_train, metadata_gr, on=['PetID'], how='left')\n",
    "if senti: df_train = pd.merge(df_train, sentiment_gr, on=['PetID'], how='left')\n",
    "if newcols: df_train = pd.merge(df_train, new_cols_ALL, on=['PetID'], how='left')\n",
    "    \n",
    "# test\n",
    "name = 'test'\n",
    "df_test = pd.read_csv(f'petfinder-adoption-prediction/{name}/{name}.csv')\n",
    "txt_emb = pd.read_csv(f'petfinder-adoption-prediction/{name}/txt_emb.csv').drop(columns=['Description', 'PhotoAmt'])\n",
    "metadata_gr = pd.read_csv(f'petfinder-adoption-prediction/{name}/metadata_gr.csv')\n",
    "sentiment_gr = pd.read_csv(f'petfinder-adoption-prediction/{name}/sentiment_gr.csv')\n",
    "if beit:\n",
    "    beit_emb = pd.read_csv(f'petfinder-adoption-prediction/{name}/beit_emb.csv')\n",
    "    beit_emb = beit_emb.drop(columns=['Description', 'PhotoAmt'])\n",
    "df_test = pd.merge(df_test, beit_emb, on=['PetID'], how='left')\n",
    "if bert: df_test = pd.merge(df_test, bert_emb, on=['PetID'], how='left')\n",
    "if breed: \n",
    "    df_test = pd.merge(df_test, breed_emb, left_on=['Breed1'], right_on=['BreedID'], how='left')\n",
    "    df_test = df_test.drop(columns=['BreedID'])    \n",
    "if txt: df_test = pd.merge(df_test, txt_emb, on=['PetID'], how='left')\n",
    "if meta: df_test = pd.merge(df_test, metadata_gr, on=['PetID'], how='left')\n",
    "if senti: df_test = pd.merge(df_test, sentiment_gr, on=['PetID'], how='left')\n",
    "if newcols: df_test = pd.merge(df_test, new_cols_ALL, on=['PetID'], how='left')\n",
    "\n",
    "# get dummies\n",
    "# categorical_features = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3']\n",
    "categorical_features = ['Type', 'Gender', 'Color1', 'Color2', 'Color3']\n",
    "\n",
    "df_test['AdoptionSpeed'] = -1\n",
    "df_main = pd.concat([df_train, df_test], axis=0, ignore_index=True)\n",
    "df_main = pd.get_dummies(df_main, columns=categorical_features)\n",
    "df_train = df_main[df_main['AdoptionSpeed'] > -1]\n",
    "df_test = df_main[df_main['AdoptionSpeed'] == -1]\n",
    "\n",
    "# get dataset\n",
    "X_train = df_train.drop(columns=['AdoptionSpeed', 'Name', 'Description', 'PetID', 'RescuerID', 'Breed1', 'Breed2'])  # Features\n",
    "y_train = df_train['AdoptionSpeed']\n",
    "X_test = df_test.drop(columns=['AdoptionSpeed', 'Name', 'Description', 'PetID', 'RescuerID', 'Breed1', 'Breed2'])  # Features\n",
    "Y_test = df_test['AdoptionSpeed']\n",
    "\n",
    "# # parse inpput\n",
    "test_data = pd.read_csv(f'petfinder-adoption-prediction/test/test.csv')\n",
    "# X_train, y_train = PreProcessTrain(\n",
    "#     df_train, bert_emb, breed_emb, beit_emb, new_cols_ALL,\n",
    "#     bert, beit, breed, txt, meta, senti, newcols\n",
    "# )\n",
    "# X_test = PreProcessTest(\n",
    "#     df_test, bert_emb, breed_emb, beit_emb, new_cols_ALL,\n",
    "#     bert, beit, breed, txt, meta, senti, newcols\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58490028-1a2b-4ab8-83cf-796ca3b89eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>Dewormed</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Fee</th>\n",
       "      <th>State</th>\n",
       "      <th>...</th>\n",
       "      <th>Color2_4</th>\n",
       "      <th>Color2_5</th>\n",
       "      <th>Color2_6</th>\n",
       "      <th>Color2_7</th>\n",
       "      <th>Color3_0</th>\n",
       "      <th>Color3_3</th>\n",
       "      <th>Color3_4</th>\n",
       "      <th>Color3_5</th>\n",
       "      <th>Color3_6</th>\n",
       "      <th>Color3_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>41326</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41401</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>41401</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14988</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14989</th>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14990</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>41326</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14991</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41336</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14992</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41332</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14993 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  MaturitySize  FurLength  Vaccinated  Dewormed  Sterilized  Health  \\\n",
       "0        3             1          1           2         2           2       1   \n",
       "1        1             2          2           3         3           3       1   \n",
       "2        1             2          2           1         1           2       1   \n",
       "3        4             2          1           1         1           2       1   \n",
       "4        1             2          1           2         2           2       1   \n",
       "...    ...           ...        ...         ...       ...         ...     ...   \n",
       "14988    2             2          2           2         2           2       1   \n",
       "14989   60             2          2           1         1           1       1   \n",
       "14990    2             3          2           2         1           3       1   \n",
       "14991    9             1          1           1         1           1       1   \n",
       "14992    1             2          1           2         2           2       1   \n",
       "\n",
       "       Quantity  Fee  State  ...  Color2_4  Color2_5  Color2_6  Color2_7  \\\n",
       "0             1  100  41326  ...     False     False     False      True   \n",
       "1             1    0  41401  ...     False     False     False     False   \n",
       "2             1    0  41326  ...     False     False     False      True   \n",
       "3             1  150  41401  ...     False     False     False     False   \n",
       "4             1    0  41326  ...     False     False     False     False   \n",
       "...         ...  ...    ...  ...       ...       ...       ...       ...   \n",
       "14988         4    0  41326  ...     False     False     False     False   \n",
       "14989         2    0  41326  ...      True     False     False     False   \n",
       "14990         5   30  41326  ...     False     False      True     False   \n",
       "14991         1    0  41336  ...     False     False     False      True   \n",
       "14992         1    0  41332  ...     False     False     False     False   \n",
       "\n",
       "       Color3_0  Color3_3  Color3_4  Color3_5  Color3_6  Color3_7  \n",
       "0          True     False     False     False     False     False  \n",
       "1          True     False     False     False     False     False  \n",
       "2          True     False     False     False     False     False  \n",
       "3          True     False     False     False     False     False  \n",
       "4          True     False     False     False     False     False  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "14988      True     False     False     False     False     False  \n",
       "14989     False     False     False     False     False      True  \n",
       "14990     False     False     False     False     False      True  \n",
       "14991      True     False     False     False     False     False  \n",
       "14992      True     False     False     False     False     False  \n",
       "\n",
       "[14993 rows x 64 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.fillna(0)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fc5fec5-caba-400d-962a-5ff3d3baa605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = OptunaTune(X_train, y_train, nt=50, nj=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f32d5f1-7c02-4ed9-92e3-3aaa833fef9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.18049322719122451. params: {'max_depth': 10, 'minbucket': 1, 'regression_lambda': 0.01, 'ls_num_tree_restarts': 50}. time: 993.5479788780212\n",
      "loss: 0.2658158741488822. params: {'max_depth': 10, 'minbucket': 1, 'regression_lambda': 0.05, 'ls_num_tree_restarts': 50}. time: 144.70159792900085\n",
      "loss: 0.17839541580284923. params: {'max_depth': 10, 'minbucket': 1, 'regression_lambda': 0.1, 'ls_num_tree_restarts': 50}. time: 140.23096919059753\n",
      "loss: 0.18217813824053397. params: {'max_depth': 10, 'minbucket': 2, 'regression_lambda': 0.01, 'ls_num_tree_restarts': 50}. time: 138.55543994903564\n",
      "loss: 0.20404581667639743. params: {'max_depth': 10, 'minbucket': 2, 'regression_lambda': 0.05, 'ls_num_tree_restarts': 50}. time: 145.32408690452576\n",
      "loss: 0.25547979825996414. params: {'max_depth': 10, 'minbucket': 2, 'regression_lambda': 0.1, 'ls_num_tree_restarts': 50}. time: 132.74078178405762\n",
      "loss: 0.19902588061314352. params: {'max_depth': 10, 'minbucket': 4, 'regression_lambda': 0.01, 'ls_num_tree_restarts': 50}. time: 130.38078117370605\n",
      "loss: 0.2833687888012344. params: {'max_depth': 10, 'minbucket': 4, 'regression_lambda': 0.05, 'ls_num_tree_restarts': 50}. time: 139.46830415725708\n",
      "loss: 0.19580043111532752. params: {'max_depth': 10, 'minbucket': 4, 'regression_lambda': 0.1, 'ls_num_tree_restarts': 50}. time: 141.457701921463\n",
      "loss: 0.1977391988139916. params: {'max_depth': 10, 'minbucket': 8, 'regression_lambda': 0.01, 'ls_num_tree_restarts': 50}. time: 119.62598967552185\n",
      "loss: 0.18845506562989867. params: {'max_depth': 10, 'minbucket': 8, 'regression_lambda': 0.05, 'ls_num_tree_restarts': 50}. time: 119.70234179496765\n",
      "loss: 0.17974630779709677. params: {'max_depth': 10, 'minbucket': 8, 'regression_lambda': 0.1, 'ls_num_tree_restarts': 50}. time: 120.18062710762024\n",
      "loss: 0.18980735985450625. params: {'max_depth': 20, 'minbucket': 1, 'regression_lambda': 0.01, 'ls_num_tree_restarts': 50}. time: 415.7649977207184\n",
      "loss: 0.2609008275340434. params: {'max_depth': 20, 'minbucket': 1, 'regression_lambda': 0.05, 'ls_num_tree_restarts': 50}. time: 392.49664306640625\n",
      "loss: 0.19192971530152492. params: {'max_depth': 20, 'minbucket': 1, 'regression_lambda': 0.1, 'ls_num_tree_restarts': 50}. time: 387.34075713157654\n",
      "loss: 0.19683335456822093. params: {'max_depth': 20, 'minbucket': 2, 'regression_lambda': 0.01, 'ls_num_tree_restarts': 50}. time: 435.39764618873596\n",
      "loss: 0.18258153789198683. params: {'max_depth': 20, 'minbucket': 2, 'regression_lambda': 0.05, 'ls_num_tree_restarts': 50}. time: 422.3659839630127\n",
      "loss: 0.26774960937341374. params: {'max_depth': 20, 'minbucket': 2, 'regression_lambda': 0.1, 'ls_num_tree_restarts': 50}. time: 432.0035071372986\n",
      "loss: 0.2837437038410586. params: {'max_depth': 20, 'minbucket': 4, 'regression_lambda': 0.01, 'ls_num_tree_restarts': 50}. time: 355.31711292266846\n",
      "loss: 0.2778835837274064. params: {'max_depth': 20, 'minbucket': 4, 'regression_lambda': 0.05, 'ls_num_tree_restarts': 50}. time: 364.36239886283875\n",
      "loss: 0.26575164552639985. params: {'max_depth': 20, 'minbucket': 4, 'regression_lambda': 0.1, 'ls_num_tree_restarts': 50}. time: 372.9721779823303\n",
      "loss: 0.29320914788819585. params: {'max_depth': 20, 'minbucket': 8, 'regression_lambda': 0.01, 'ls_num_tree_restarts': 50}. time: 251.0210406780243\n",
      "loss: 0.2738219190124941. params: {'max_depth': 20, 'minbucket': 8, 'regression_lambda': 0.05, 'ls_num_tree_restarts': 50}. time: 250.30142188072205\n",
      "loss: 0.2762989448437715. params: {'max_depth': 20, 'minbucket': 8, 'regression_lambda': 0.1, 'ls_num_tree_restarts': 50}. time: 246.89147806167603\n",
      "loss: 0.28663565170731764. params: {'max_depth': 40, 'minbucket': 1, 'regression_lambda': 0.01, 'ls_num_tree_restarts': 50}. time: 719.2460501194\n",
      "loss: 0.20381843699202107. params: {'max_depth': 40, 'minbucket': 1, 'regression_lambda': 0.05, 'ls_num_tree_restarts': 50}. time: 307.68478298187256\n",
      "loss: 0.2247398006320176. params: {'max_depth': 40, 'minbucket': 1, 'regression_lambda': 0.1, 'ls_num_tree_restarts': 50}. time: 302.78587222099304\n",
      "loss: 0.2507807938169371. params: {'max_depth': 40, 'minbucket': 2, 'regression_lambda': 0.01, 'ls_num_tree_restarts': 50}. time: 452.9912278652191\n",
      "loss: 0.29062652481675166. params: {'max_depth': 40, 'minbucket': 2, 'regression_lambda': 0.05, 'ls_num_tree_restarts': 50}. time: 480.1424081325531\n",
      "loss: 0.19020842535883764. params: {'max_depth': 40, 'minbucket': 2, 'regression_lambda': 0.1, 'ls_num_tree_restarts': 50}. time: 463.23069071769714\n",
      "loss: 0.28366443704864275. params: {'max_depth': 40, 'minbucket': 4, 'regression_lambda': 0.01, 'ls_num_tree_restarts': 50}. time: 397.9100069999695\n",
      "loss: 0.27007221563576034. params: {'max_depth': 40, 'minbucket': 4, 'regression_lambda': 0.05, 'ls_num_tree_restarts': 50}. time: 400.33523392677307\n",
      "loss: 0.27707059580858273. params: {'max_depth': 40, 'minbucket': 4, 'regression_lambda': 0.1, 'ls_num_tree_restarts': 50}. time: 391.311240196228\n",
      "loss: 0.23423374166789812. params: {'max_depth': 40, 'minbucket': 8, 'regression_lambda': 0.01, 'ls_num_tree_restarts': 50}. time: 252.40894889831543\n",
      "loss: 0.23395678731679337. params: {'max_depth': 40, 'minbucket': 8, 'regression_lambda': 0.05, 'ls_num_tree_restarts': 50}. time: 266.7698709964752\n",
      "loss: 0.19544012131451194. params: {'max_depth': 40, 'minbucket': 8, 'regression_lambda': 0.1, 'ls_num_tree_restarts': 50}. time: 253.97536087036133\n",
      "loss: 0.2564871264571641. params: {'max_depth': 80, 'minbucket': 1, 'regression_lambda': 0.01, 'ls_num_tree_restarts': 50}. time: 609.4745960235596\n",
      "loss: 0.18770847060610518. params: {'max_depth': 80, 'minbucket': 1, 'regression_lambda': 0.05, 'ls_num_tree_restarts': 50}. time: 298.4664378166199\n",
      "loss: 0.19158748038525197. params: {'max_depth': 80, 'minbucket': 1, 'regression_lambda': 0.1, 'ls_num_tree_restarts': 50}. time: 302.97232818603516\n",
      "loss: 0.23321496756307358. params: {'max_depth': 80, 'minbucket': 2, 'regression_lambda': 0.01, 'ls_num_tree_restarts': 50}. time: 506.0162920951843\n",
      "loss: 0.2776242529874482. params: {'max_depth': 80, 'minbucket': 2, 'regression_lambda': 0.05, 'ls_num_tree_restarts': 50}. time: 469.0045471191406\n",
      "loss: 0.2463322729780737. params: {'max_depth': 80, 'minbucket': 2, 'regression_lambda': 0.1, 'ls_num_tree_restarts': 50}. time: 464.21462988853455\n",
      "loss: 0.23175936773290762. params: {'max_depth': 80, 'minbucket': 4, 'regression_lambda': 0.01, 'ls_num_tree_restarts': 50}. time: 404.37116503715515\n",
      "loss: 0.2704107011490997. params: {'max_depth': 80, 'minbucket': 4, 'regression_lambda': 0.05, 'ls_num_tree_restarts': 50}. time: 395.1141412258148\n",
      "loss: 0.19795059218097089. params: {'max_depth': 80, 'minbucket': 4, 'regression_lambda': 0.1, 'ls_num_tree_restarts': 50}. time: 389.123015165329\n",
      "loss: 0.29500457210899134. params: {'max_depth': 80, 'minbucket': 8, 'regression_lambda': 0.01, 'ls_num_tree_restarts': 50}. time: 256.720153093338\n",
      "loss: 0.19399830737499923. params: {'max_depth': 80, 'minbucket': 8, 'regression_lambda': 0.05, 'ls_num_tree_restarts': 50}. time: 248.97675490379333\n",
      "loss: 0.19522018074192438. params: {'max_depth': 80, 'minbucket': 8, 'regression_lambda': 0.1, 'ls_num_tree_restarts': 50}. time: 248.99310302734375\n"
     ]
    }
   ],
   "source": [
    "X_train_, X_valid_, y_train_, y_valid_ = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "\n",
    "for max_depth in [10, 20, 40, 80]:\n",
    "    for minbucket in [1, 2, 4, 8]:\n",
    "        for regression_lambda in [0.01, 0.05, 0.1]:\n",
    "            param = {\n",
    "                'max_depth': max_depth,\n",
    "                'minbucket': minbucket,\n",
    "                'regression_lambda': regression_lambda,\n",
    "                'ls_num_tree_restarts': 50\n",
    "            } \n",
    "            grid = iai.GridSearch(\n",
    "                iai.OptimalTreeRegressor(\n",
    "                    **param, \n",
    "                ),\n",
    "            )\n",
    "            start_time = time.time()\n",
    "            grid.fit(X_train_, y_train_)\n",
    "            preds = grid.predict(X_valid_)\n",
    "            \n",
    "            optR = OptimizedRounder()\n",
    "            optR.fit(preds, y_valid_.values)\n",
    "            coefficients = optR.coefficients()\n",
    "            pred_valid = optR.predict(preds, coefficients)\n",
    "            loss = cohen_kappa_score(y_valid_, pred_valid, weights='quadratic')\n",
    "            end_time = time.time()\n",
    "            print(f'loss: {loss}. params: {param}. time: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c49273a4-4c51-45c4-bc05-e5795dacb4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code took 750.0688607692719 seconds to run.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ Warning: This copy of Interpretable AI software is for academic purposes only and not for commercial use.\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "    'max_depth': 10,\n",
    "    'minbucket': 2,\n",
    "    'regression_lambda': 0.01,\n",
    "    'ls_num_tree_restarts': 10\n",
    "}\n",
    "\n",
    "grid = iai.GridSearch(\n",
    "    iai.OptimalTreeRegressor(\n",
    "        **param, \n",
    "    ),\n",
    ")\n",
    "start_time = time.time()\n",
    "grid.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "print(f\"The code took {end_time - start_time} seconds to run.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5365f49a-8105-428c-81ab-13dd08dfe2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22465400763783672\n"
     ]
    }
   ],
   "source": [
    "preds = grid.predict(X_train)\n",
    "optR = OptimizedRounder()\n",
    "optR.fit(preds, y_train.values)\n",
    "coefficients = optR.coefficients()\n",
    "pred_y = optR.predict(preds, coefficients)\n",
    "print(cohen_kappa_score(y_train, pred_y, weights='quadratic'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a9545d6-f31c-492c-a730-6076b8993b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          PetID AdoptionSpeed\n",
      "0     e2dfc2935             3\n",
      "1     f153b465f             2\n",
      "2     3c90f3f54             2\n",
      "3     e02abc8a3             3\n",
      "4     09f0df7d1             3\n",
      "...         ...           ...\n",
      "3967  ae57f8d52             3\n",
      "3968  83432904d             3\n",
      "3969  399013029             3\n",
      "3970  fd80b8c80             3\n",
      "3971  493ed84ae             3\n",
      "\n",
      "[3972 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(f'petfinder-adoption-prediction/test/test.csv')\n",
    "TestResultDF_LGBMReg(grid, optR, coefficients, X_test, f'Results/octnotune.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9605fa-0b23-4fad-b6d5-8d94a6ad102e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myjulia",
   "language": "python",
   "name": "myjulia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
